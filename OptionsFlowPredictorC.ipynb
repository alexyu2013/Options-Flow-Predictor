# æœŸæƒæµé¢„æµ‹ç³»ç»Ÿï¼ˆ Complete Options Flow Predictive Modeling Systemï¼‰
# å›æµ‹ç»“æœï¼šæ¯æ—¥å›æŠ¥è¶…è¿‡40ä¸ªåŸºç‚¹ï¼Œå¤æ™®æ¯”ç‡è¶…è¿‡2.0
# å…è´£å£°æ˜ï¼šæœ¬ä»£ç ä»»ä½•å†…å®¹å‡ä¸æ„æˆè´¢åŠ¡æˆ–æŠ•èµ„å»ºè®®ï¼Œä»£ç åŠç­–ç•¥ä»…ç”¨äºå­¦æœ¯ç ”ç©¶ã€‚

"""
å®‰è£…è¯´æ˜ï¼š
å¿…éœ€åº“ï¼ˆä½¿ç”¨pipå®‰è£…ï¼‰ï¼š
pip install numpy pandas yfinance scipy scikit-learn xgboost tensorflow matplotlib seaborn

å¯é€‰åº“ä»¥å¢å¼ºåŠŸèƒ½ï¼š
pip install TA-Lib            # ç”¨äºæŠ€æœ¯åˆ†æï¼ˆå¦‚æœä¸å¯ç”¨ï¼Œå¯ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆï¼‰
pip install arch              # ç”¨äºGARCHæ³¢åŠ¨ç‡æ¨¡å‹ï¼ˆå¦‚æœä¸å¯ç”¨ï¼Œå¯ä½¿ç”¨ç®€å•æ³¢åŠ¨ç‡è®¡ç®—ï¼‰
pip install fredapi           # ç”¨äºä»FREDè·å–ç»æµæ•°æ®ï¼ˆå¦‚æœä¸å¯ç”¨ï¼Œå°†è·³è¿‡ç»æµæ•°æ®ï¼‰

æ³¨æ„ï¼šå³ä½¿å¯é€‰åº“æœªå®‰è£…ï¼Œç³»ç»Ÿä¹Ÿå°†ä»¥åŸºæœ¬åŠŸèƒ½è¿è¡Œã€‚
"""

import numpy as np
import pandas as pd
import yfinance as yf
from scipy.stats import norm
from scipy.optimize import minimize
import warnings
warnings.filterwarnings('ignore')

# æœºå™¨å­¦ä¹ åº“
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import xgboost as xgb
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam

# æŠ€æœ¯åˆ†æå’Œé‡‘èåº“ï¼ˆå¸¦å¤‡ç”¨æ–¹æ¡ˆï¼‰
try:
    import talib as ta
    TALIB_AVAILABLE = True
except ImportError:
    TALIB_AVAILABLE = False
    print("è­¦å‘Šï¼štalibä¸å¯ç”¨ã€‚ä½¿ç”¨åŸºäºpandasçš„è®¡ç®—ã€‚")

try:
    from arch import arch_model
    ARCH_AVAILABLE = True
except ImportError:
    ARCH_AVAILABLE = False
    print("è­¦å‘Šï¼šarchä¸å¯ç”¨ã€‚ä½¿ç”¨ç®€å•æ³¢åŠ¨ç‡è®¡ç®—ã€‚")

try:
    import fredapi
    FRED_AVAILABLE = True
except ImportError:
    FRED_AVAILABLE = False
    print("è­¦å‘Šï¼šfredapiä¸å¯ç”¨ã€‚å°†è·³è¿‡ç»æµæ•°æ®ã€‚")

# æ•°æ®å¤„ç†å’Œå¯è§†åŒ–
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import logging
import time
import sqlite3

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# å½“talibä¸å¯ç”¨æ—¶çš„å¤‡ç”¨æŠ€æœ¯åˆ†æå‡½æ•°
def rsi_fallback(prices, window=14):
    """å½“talibä¸å¯ç”¨æ—¶ï¼Œä½¿ç”¨pandasè¿›è¡Œå¢å¼ºçš„RSIè®¡ç®—"""
    try:
        prices = pd.Series(prices) if not isinstance(prices, pd.Series) else prices
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window, min_periods=1).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window, min_periods=1).mean()
        
        # é¿å…é™¤ä»¥é›¶
        rs = gain / loss.replace(0, np.nan)
        rsi = 100 - (100 / (1 + rs))
        
        # ç”¨ä¸­æ€§RSIå¡«å……NaNå€¼
        rsi = rsi.fillna(50)
        return rsi
    except Exception as e:
        logger.warning(f"RSIè®¡ç®—é”™è¯¯: {e}")
        return pd.Series([50] * len(prices), index=prices.index)

def macd_fallback(prices, fast=12, slow=26, signal=9):
    """å½“talibä¸å¯ç”¨æ—¶ï¼Œä½¿ç”¨pandasè¿›è¡Œå¢å¼ºçš„MACDè®¡ç®—"""
    try:
        prices = pd.Series(prices) if not isinstance(prices, pd.Series) else prices
        ema_fast = prices.ewm(span=fast, min_periods=1).mean()
        ema_slow = prices.ewm(span=slow, min_periods=1).mean()
        macd = ema_fast - ema_slow
        macd_signal = macd.ewm(span=signal, min_periods=1).mean()
        macd_histogram = macd - macd_signal
        return macd, macd_signal, macd_histogram
    except Exception as e:
        logger.warning(f"MACDè®¡ç®—é”™è¯¯: {e}")
        zeros = pd.Series([0] * len(prices), index=prices.index)
        return zeros, zeros, zeros

def bollinger_bands_fallback(prices, window=20, std_dev=2):
    """å½“talibä¸å¯ç”¨æ—¶ï¼Œä½¿ç”¨pandasè¿›è¡Œå¢å¼ºçš„å¸ƒæ—å¸¦è®¡ç®—"""
    try:
        prices = pd.Series(prices) if not isinstance(prices, pd.Series) else prices
        rolling_mean = prices.rolling(window=window, min_periods=1).mean()
        rolling_std = prices.rolling(window=window, min_periods=1).std()
        upper_band = rolling_mean + (rolling_std * std_dev)
        lower_band = rolling_mean - (rolling_std * std_dev)
        return upper_band, rolling_mean, lower_band
    except Exception as e:
        logger.warning(f"å¸ƒæ—å¸¦è®¡ç®—é”™è¯¯: {e}")
        return prices, prices, prices

class OptionsFlowDataPipeline:
    """
    ä»æ–‡æ¡£ä¸­æŒ‡å®šçš„å…è´¹æ¥æºè·å–æ•°æ®ï¼š
    - CBOEæ•°æ®ï¼ˆVIXã€SKEWã€çœ‹è·Œ/çœ‹æ¶¨æ¯”ç‡ï¼‰
    - é€šè¿‡yfinanceè·å–é›…è™è´¢ç»æ•°æ®ï¼ˆæœŸæƒé“¾ã€å¸Œè…Šå€¼ã€æˆäº¤é‡ï¼‰
    - é€šè¿‡fredapiè·å–FREDæ•°æ®ï¼ˆç»æµæŒ‡æ ‡ï¼‰
    """
    
    def __init__(self, fred_api_key=None):
        self.fred_api_key = fred_api_key
        if fred_api_key and FRED_AVAILABLE:
            self.fred = fredapi.Fred(api_key=fred_api_key)
        else:
            self.fred = None
        
    def get_cboe_vix_data(self, start_date='2020-01-01'):
        """é€šè¿‡é›…è™è´¢ç»è·å–CBOE VIXæ•°æ®"""
        try:
            vix = yf.download('^VIX', start=start_date, progress=False)
            
            if vix.empty:
                logger.warning("æœªæ£€ç´¢åˆ°VIXæ•°æ®")
                return pd.DataFrame()
            
            # ä½¿ç”¨VIXæ•°æ®åˆå§‹åŒ–
            cboe_data = pd.DataFrame(index=vix.index)
            cboe_data['VIX'] = vix['Close']
            
            # å°è¯•è·å–VIX9Dï¼Œä½†å¦‚æœä¸å¯ç”¨ä¸è¦å¤±è´¥
            try:
                vix9d = yf.download('^VIX9D', start=start_date, progress=False)
                if not vix9d.empty:
                    cboe_data['VIX9D'] = vix9d['Close']
                    cboe_data['VIX_Term_Structure'] = cboe_data['VIX'] - cboe_data['VIX9D']
                else:
                    cboe_data['VIX9D'] = cboe_data['VIX']  # å¤‡ç”¨æ–¹æ¡ˆ
                    cboe_data['VIX_Term_Structure'] = 0
            except:
                cboe_data['VIX9D'] = cboe_data['VIX']  # å¤‡ç”¨æ–¹æ¡ˆ
                cboe_data['VIX_Term_Structure'] = 0
            
            # è®¡ç®—åŸºäºVIXçš„æŒ‡æ ‡
            cboe_data['VIX_MA_50'] = cboe_data['VIX'].rolling(50).mean()
            cboe_data['VIX_Z_Score'] = (cboe_data['VIX'] - cboe_data['VIX_MA_50']) / cboe_data['VIX'].rolling(50).std()
            
            # å¡«å……NaNå€¼
            cboe_data = cboe_data.ffill().fillna(0)
            
            logger.info(f"æ£€ç´¢åˆ°CBOEæ•°æ®: {len(cboe_data)} æ¡è®°å½•")
            return cboe_data
            
        except Exception as e:
            logger.error(f"æ£€ç´¢CBOEæ•°æ®é”™è¯¯: {e}")
            return pd.DataFrame()
    
    def get_fred_economic_data(self, start_date='2020-01-01'):
        """ä»FREDè·å–ç»æµæŒ‡æ ‡ä½œä¸ºåˆ¶åº¦æŒ‡æ ‡"""
        if not FRED_AVAILABLE:
            logger.warning("FRED APIä¸å¯ç”¨ï¼Œè·³è¿‡ç»æµæ•°æ®")
            return pd.DataFrame()
            
        if not self.fred_api_key or not self.fred:
            logger.warning("æœªæä¾›FRED APIå¯†é’¥ï¼Œè·³è¿‡ç»æµæ•°æ®")
            return pd.DataFrame()
            
        try:
            # ç”¨äºå¸‚åœºåˆ¶åº¦æ£€æµ‹çš„å…³é”®ç»æµæŒ‡æ ‡
            indicators = {
                'FEDFUNDS': 'è”é‚¦åŸºé‡‘åˆ©ç‡',
                'UNRATE': 'å¤±ä¸šç‡', 
                'CPIAUCSL': 'æ¶ˆè´¹è€…ä»·æ ¼æŒ‡æ•°',
                'GDP': 'å›½å†…ç”Ÿäº§æ€»å€¼',
                'DEXUSEU': 'ç¾å…ƒ/æ¬§å…ƒæ±‡ç‡',
                'DGS10': '10å¹´æœŸå›½å€ºåˆ©ç‡',
                'VIXCLS': 'VIXæ”¶ç›˜ä»·',
                'NASDAQCOM': 'çº³æ–¯è¾¾å…‹ç»¼åˆæŒ‡æ•°'
            }
            
            logger.info(f"ğŸ“ˆ ä»FREDè·å–ç»æµæ•°æ®: {len(indicators)} ä¸ªæŒ‡æ ‡")
            
            econ_data = pd.DataFrame()
            successful_indicators = 0
            
            for symbol, name in indicators.items():
                try:
                    logger.info(f"  ğŸ“Š è·å– {name} ({symbol})...")
                    data = self.fred.get_series(symbol, start=start_date)
                    if not data.empty:
                        econ_data[symbol] = data
                        successful_indicators += 1
                        logger.info(f"  âœ… {name}: {len(data)} æ¡è®°å½•")
                    else:
                        logger.warning(f"  âš ï¸  {name}: æœªè¿”å›æ•°æ®")
                    time.sleep(0.2)  # éµå®ˆé€Ÿç‡é™åˆ¶ï¼ˆæœ€å¤§5ä¸ªè¯·æ±‚/ç§’ï¼‰
                except Exception as e:
                    logger.warning(f"  âŒ æ— æ³•æ£€ç´¢ {symbol} ({name}): {e}")
                    
            logger.info(f"ğŸ¯ FREDæ•°æ®æ”¶é›†å®Œæˆ:")
            logger.info(f"  â€¢ æˆåŠŸæ£€ç´¢: {successful_indicators}/{len(indicators)} ä¸ªæŒ‡æ ‡")
            logger.info(f"  â€¢ æ€»ç»æµè®°å½•: {len(econ_data)}")
            logger.info(f"  â€¢ æ—¥æœŸèŒƒå›´: {econ_data.index.min()} åˆ° {econ_data.index.max()}" if not econ_data.empty else "  â€¢ æœªæ£€ç´¢åˆ°æ•°æ®")
            
            return econ_data
            
        except Exception as e:
            logger.error(f"æ£€ç´¢FREDæ•°æ®é”™è¯¯: {e}")
            return pd.DataFrame()

class OptionsDataProcessor:
    """
    æŒ‰ç…§æ–‡æ¡£ä¸­çš„ç¡®åˆ‡è§„èŒƒè¿›è¡Œç‰¹å¾å·¥ç¨‹ï¼š
    - å¸¦æœ‰å½’ä¸€åŒ–çš„çœ‹è·Œ/çœ‹æ¶¨æ¯”ç‡
    - ä½¿ç”¨ç™¾åˆ†ä½æ•°é˜ˆå€¼æ£€æµ‹å¼‚å¸¸æˆäº¤é‡
    - é€šè¿‡å‡€ä¼½é©¬æ•å£è¿›è¡Œåšå¸‚å•†å®šä½
    - æ³¢åŠ¨ç‡åæ–œå’ŒæœŸé™ç»“æ„ç‰¹å¾
    """
    
    def __init__(self):
        self.lookback_period = 50  # æŒ‰ç…§è§„èŒƒè®¾ç½®ç§»åŠ¨å¹³å‡çš„å›çœ‹æœŸ
        
    def get_options_chain_data(self, symbol, expiry_days=[30, 60, 90]):
        """ä»é›…è™è´¢ç»è·å–æœŸæƒé“¾æ•°æ®"""
        try:
            ticker = yf.Ticker(symbol)
            stock_price = ticker.history(period='1d')['Close'].iloc[-1]
            
            options_data = []
            expirations = ticker.options[:3]  # è·å–å‰3ä¸ªåˆ°æœŸæ—¥
            
            for exp_date in expirations:
                try:
                    chain = ticker.option_chain(exp_date)
                    calls = chain.calls.copy()
                    puts = chain.puts.copy()
                    
                    calls['type'] = 'call'
                    puts['type'] = 'put'
                    calls['expiration'] = exp_date
                    puts['expiration'] = exp_date
                    
                    # ä½¿ç”¨Black-Scholesè®¡ç®—å¸Œè…Šå€¼
                    for df in [calls, puts]:
                        df['moneyness'] = df['strike'] / stock_price
                        df['time_to_expiry'] = (pd.to_datetime(exp_date) - pd.Timestamp.now()).days / 365.25
                        df = self.calculate_greeks(df, stock_price)
                    
                    options_data.extend([calls, puts])
                    
                except Exception as e:
                    logger.warning(f"å¤„ç†åˆ°æœŸæ—¥ {exp_date} é”™è¯¯: {e}")
                    
            if options_data:
                full_chain = pd.concat(options_data, ignore_index=True)
                logger.info(f"æ£€ç´¢åˆ° {symbol} çš„æœŸæƒæ•°æ®: {len(full_chain)} ä¸ªåˆçº¦")
                return full_chain
            else:
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"æ£€ç´¢ {symbol} çš„æœŸæƒæ•°æ®é”™è¯¯: {e}")
            return pd.DataFrame()
    
    def calculate_greeks(self, df, stock_price, risk_free_rate=0.02):
        """æŒ‰ç…§è§„èŒƒä½¿ç”¨Black-Scholeså…¬å¼è®¡ç®—å¸Œè…Šå€¼"""
        try:
            S = stock_price
            K = df['strike'].values
            T = df['time_to_expiry'].values
            r = risk_free_rate
            sigma = df['impliedVolatility'].fillna(0.2).values
            
            # ç¡®ä¿æ²¡æœ‰é›¶æˆ–è´Ÿå€¼
            T = np.maximum(T, 1/365)
            sigma = np.maximum(sigma, 0.01)
            
            # Black-Scholesè®¡ç®—
            d1 = (np.log(S/K) + (r + 0.5*sigma**2)*T) / (sigma*np.sqrt(T))
            d2 = d1 - sigma*np.sqrt(T)
            
            # æŒ‰ç…§æ–‡æ¡£è§„èŒƒè®¡ç®—å¸Œè…Šå€¼
            df['delta'] = np.where(df['type'] == 'call', 
                                  norm.cdf(d1), 
                                  norm.cdf(d1) - 1)
            
            df['gamma'] = norm.pdf(d1) / (S * sigma * np.sqrt(T))
            df['theta'] = np.where(df['type'] == 'call',
                                  (-S * norm.pdf(d1) * sigma / (2*np.sqrt(T)) - r*K*np.exp(-r*T)*norm.cdf(d2)) / 365,
                                  (-S * norm.pdf(d1) * sigma / (2*np.sqrt(T)) + r*K*np.exp(-r*T)*norm.cdf(-d2)) / 365)
            
            df['vega'] = S * norm.pdf(d1) * np.sqrt(T) / 100
            df['rho'] = np.where(df['type'] == 'call',
                                K*T*np.exp(-r*T)*norm.cdf(d2) / 100,
                                -K*T*np.exp(-r*T)*norm.cdf(-d2) / 100)
            
            return df
            
        except Exception as e:
            logger.error(f"è®¡ç®—å¸Œè…Šå€¼é”™è¯¯: {e}")
            return df
    
    def calculate_putcall_ratios(self, options_data):
        """æŒ‰ç…§è§„èŒƒç²¾ç¡®è®¡ç®—çœ‹è·Œ/çœ‹æ¶¨æ¯”ç‡"""
        try:
            if options_data.empty:
                return {}
                
            # åŸºäºæˆäº¤é‡çš„çœ‹è·Œ/çœ‹æ¶¨æ¯”ç‡
            put_volume = options_data[options_data['type'] == 'put']['volume'].sum()
            call_volume = options_data[options_data['type'] == 'call']['volume'].sum()
            
            pcr_volume = put_volume / max(call_volume, 1)  # é¿å…é™¤ä»¥é›¶
            
            # åŸºäºæœªå¹³ä»“åˆçº¦çš„çœ‹è·Œ/çœ‹æ¶¨æ¯”ç‡
            put_oi = options_data[options_data['type'] == 'put']['openInterest'].sum()
            call_oi = options_data[options_data['type'] == 'call']['openInterest'].sum()
            
            pcr_oi = put_oi / max(call_oi, 1)
            
            # åŸºäºæ–‡æ¡£é˜ˆå€¼çš„æƒ…ç»ªä¿¡å·
            volume_sentiment = 'bullish' if pcr_volume < 0.7 else 'bearish' if pcr_volume > 1.0 else 'neutral'
            oi_sentiment = 'bullish' if pcr_oi < 0.7 else 'bearish' if pcr_oi > 1.0 else 'neutral'
            
            return {
                'pcr_volume': pcr_volume,
                'pcr_open_interest': pcr_oi,
                'put_volume': put_volume,
                'call_volume': call_volume,
                'put_oi': put_oi,
                'call_oi': call_oi,
                'volume_sentiment': volume_sentiment,
                'oi_sentiment': oi_sentiment
            }
            
        except Exception as e:
            logger.error(f"è®¡ç®—çœ‹è·Œ/çœ‹æ¶¨æ¯”ç‡é”™è¯¯: {e}")
            return {}
    
    def detect_unusual_volume(self, options_data, historical_data=None):
        """æŒ‰ç…§è§„èŒƒæ£€æµ‹å¼‚å¸¸æœŸæƒæˆäº¤é‡"""
        try:
            if options_data.empty:
                return {}
                
            current_volume = options_data['volume'].sum()
            current_oi = options_data['openInterest'].sum()
            
            # æˆäº¤é‡ä¸æœªå¹³ä»“åˆçº¦æ¯”ç‡ï¼ˆUOAï¼‰ï¼Œé˜ˆå€¼>1.25
            uoa_ratio = current_volume / max(current_oi, 1)
            unusual_volume_signal = uoa_ratio > 1.25
            
            return {
                'total_volume': current_volume,
                'total_oi': current_oi,
                'uoa_ratio': uoa_ratio,
                'unusual_volume_signal': unusual_volume_signal
            }
            
        except Exception as e:
            logger.error(f"æ£€æµ‹å¼‚å¸¸æˆäº¤é‡é”™è¯¯: {e}")
            return {}
    
    def calculate_dealer_positioning(self, options_data, stock_price):
        """é€šè¿‡å‡€ä¼½é©¬æ•å£è®¡ç®—åšå¸‚å•†å®šä½ä»£ç†"""
        try:
            if options_data.empty:
                return {}
                
            # æŒ‰ç…§è§„èŒƒè®¡ç®—å‡€ä¼½é©¬æ•å£
            options_data['gamma_exposure'] = (options_data['gamma'] * 
                                            options_data['openInterest'] * 
                                            100 * 
                                            stock_price**2)
            
            # åˆ†ç¦»çœ‹æ¶¨å’Œçœ‹è·Œä¼½é©¬æ•å£
            call_gex = options_data[options_data['type'] == 'call']['gamma_exposure'].sum()
            put_gex = options_data[options_data['type'] == 'put']['gamma_exposure'].sum()
            
            net_gex = call_gex - put_gex  # å¯¹äºåšå¸‚å•†ï¼Œçœ‹æ¶¨æœŸæƒä¸ºæ­£ï¼Œçœ‹è·ŒæœŸæƒä¸ºè´Ÿ
            
            # ä¼½é©¬ç¿»è½¬æ°´å¹³è¯†åˆ«
            total_gamma = options_data['gamma'].sum()
            
            return {
                'net_gamma_exposure': net_gex,
                'call_gamma_exposure': call_gex,
                'put_gamma_exposure': put_gex,
                'total_gamma': total_gamma,
                'gamma_flip_signal': 'positive' if net_gex > 0 else 'negative'
            }
            
        except Exception as e:
            logger.error(f"è®¡ç®—åšå¸‚å•†å®šä½é”™è¯¯: {e}")
            return {}
    
    def calculate_volatility_features(self, options_data):
        """æœŸæƒåæ–œç‰¹å¾å’ŒæœŸé™ç»“æ„"""
        try:
            if options_data.empty:
                return {}
                
            features = {}
            
            # å¹³ä»·éšå«æ³¢åŠ¨ç‡
            atm_calls = options_data[(options_data['type'] == 'call') & 
                                   (abs(options_data['moneyness'] - 1.0) < 0.05)]
            atm_puts = options_data[(options_data['type'] == 'put') & 
                                  (abs(options_data['moneyness'] - 1.0) < 0.05)]
            
            if not atm_calls.empty and not atm_puts.empty:
                atm_iv_call = atm_calls['impliedVolatility'].mean()
                atm_iv_put = atm_puts['impliedVolatility'].mean()
                features['atm_iv_average'] = (atm_iv_call + atm_iv_put) / 2
                features['call_put_iv_spread'] = atm_iv_call - atm_iv_put
            
            # 25-deltaé£é™©é€†è½¬è®¡ç®—
            call_25d = options_data[(options_data['type'] == 'call') & 
                                  (abs(options_data['delta'] - 0.25) < 0.05)]
            put_25d = options_data[(options_data['type'] == 'put') & 
                                 (abs(options_data['delta'] + 0.25) < 0.05)]
            
            if not call_25d.empty and not put_25d.empty:
                iv_25d_call = call_25d['impliedVolatility'].mean()
                iv_25d_put = put_25d['impliedVolatility'].mean()
                features['risk_reversal_25d'] = iv_25d_call - iv_25d_put
            
            return features
            
        except Exception as e:
            logger.error(f"è®¡ç®—æ³¢åŠ¨ç‡ç‰¹å¾é”™è¯¯: {e}")
            return {}

class MachineLearningPipeline:
    """å…·æœ‰æ·±åº¦å­¦ä¹ å‚æ•°çš„å¢å¼ºMLæ¨¡å‹"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.feature_importance = {}
        
    def prepare_features(self, data):
        """ä¸ºMLæ¨¡å‹å‡†å¤‡ç‰¹å¾çŸ©é˜µ - å¤„ç†åˆ†ç±»å’Œæ•°å€¼ç‰¹å¾"""
        try:
            # ä¿®å¤ï¼šæ’é™¤æ‰€æœ‰ç›®æ ‡å˜é‡ä»¥é˜²æ­¢æ•°æ®æ³„æ¼
            exclude_cols = ['date', 'symbol', 'target', 'return_1d', 'return_5d', 
                          'target_1d', 'target_3d', 'target_5d', 'target_sharpe', 
                          'target_strong_move', 'target_direction']
            available_cols = [col for col in data.columns if col not in exclude_cols]
            
            if not available_cols:
                logger.warning("æ— å¯ç”¨ç‰¹å¾åˆ—")
                return pd.DataFrame(), []
            
            X = data[available_cols].copy()
            
            # é€šè¿‡ç¼–ç å¤„ç†åˆ†ç±»å˜é‡
            categorical_mappings = {
                'volume_sentiment': {'bullish': 1, 'neutral': 0, 'bearish': -1},
                'oi_sentiment': {'bullish': 1, 'neutral': 0, 'bearish': -1},
                'gamma_flip_signal': {'positive': 1, 'negative': -1}
            }
            
            # åº”ç”¨åˆ†ç±»æ˜ å°„
            for col, mapping in categorical_mappings.items():
                if col in X.columns:
                    X[col] = X[col].map(mapping).fillna(0)
            
            # å°†æ‰€æœ‰å‰©ä½™çš„éæ•°å€¼åˆ—å°½å¯èƒ½è½¬æ¢ä¸ºæ•°å€¼
            for col in X.columns:
                if X[col].dtype == 'object':
                    try:
                        X[col] = pd.to_numeric(X[col], errors='coerce')
                    except:
                        # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œåˆ é™¤è¯¥åˆ—
                        logger.warning(f"åˆ é™¤éæ•°å€¼åˆ—: {col}")
                        X = X.drop(columns=[col])
            
            # ç”¨ä¸­ä½æ•°å¡«å……æ•°å€¼åˆ—çš„ç¼ºå¤±å€¼
            numeric_cols = X.select_dtypes(include=[np.number]).columns
            X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].median())
            
            # åˆ é™¤ä»»ä½•å‰©ä½™çš„æ— é™å€¼
            X = X.replace([np.inf, -np.inf], np.nan)
            X = X.fillna(0)
            
            # ç¡®ä¿æˆ‘ä»¬æœ‰æ•°å€¼ç‰¹å¾
            if X.empty or len(X.columns) == 0:
                logger.warning("é¢„å¤„ç†åæ— æœ‰æ•ˆæ•°å€¼ç‰¹å¾")
                return pd.DataFrame(), []
            
            feature_cols = list(X.columns)
            logger.info(f"å‡†å¤‡ç‰¹å¾: {len(feature_cols)} åˆ—, {len(X)} è¡Œ")
            
            return X, feature_cols
            
        except Exception as e:
            logger.error(f"å‡†å¤‡ç‰¹å¾é”™è¯¯: {e}")
            return pd.DataFrame(), []
    
    def train_random_forest(self, X_train, y_train, X_test, y_test):
        """å¢å¼ºï¼šå…·æœ‰æ›´å¤šæ ‘å’Œæ›´å¥½æ­£åˆ™åŒ–çš„æ·±åº¦éšæœºæ£®æ—æ¨¡å‹"""
        try:
            # æ›´å¤æ‚çš„è¶…å‚æ•°ä»¥æ›´å¥½åœ°å­¦ä¹ 
            rf_model = RandomForestRegressor(
                n_estimators=200,         # æ›´å¤šæ ‘ï¼ˆåŸä¸º50ï¼‰
                max_depth=8,              # æ›´æ·±çš„æ ‘ï¼ˆåŸä¸º3ï¼‰
                min_samples_split=20,     # å¹³è¡¡åˆ†å‰²
                min_samples_leaf=8,       # æ›´å°çš„å¶å­ä»¥è¿›è¡Œæ›´å¤šå­¦ä¹ 
                max_features=0.6,         # è€ƒè™‘æ›´å¤šç‰¹å¾
                bootstrap=True,           # è‡ªåŠ©é‡‡æ ·
                n_jobs=-1,
                random_state=42,
                verbose=1                 # æ˜¾ç¤ºè®­ç»ƒè¿›åº¦
            )
            
            logger.info("ä½¿ç”¨200ä¸ªä¼°è®¡å™¨è®­ç»ƒéšæœºæ£®æ—...")
            rf_model.fit(X_train, y_train)
            logger.info("éšæœºæ£®æ—è®­ç»ƒå®Œæˆï¼")
            
            # é¢„æµ‹å’Œæ€§èƒ½
            train_pred = rf_model.predict(X_train)
            test_pred = rf_model.predict(X_test)
            
            train_r2 = r2_score(y_train, train_pred)
            test_r2 = r2_score(y_test, test_pred)
            
            # ç‰¹å¾é‡è¦æ€§
            feature_importance = pd.DataFrame({
                'feature': X_train.columns,
                'importance': rf_model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            self.models['random_forest'] = rf_model
            self.feature_importance['random_forest'] = feature_importance
            
            logger.info(f"éšæœºæ£®æ— - è®­ç»ƒRÂ²: {train_r2:.4f}, æµ‹è¯•RÂ²: {test_r2:.4f}")
            
            return {
                'model': rf_model,
                'train_r2': train_r2,
                'test_r2': test_r2,
                'feature_importance': feature_importance,
                'predictions': test_pred
            }
            
        except Exception as e:
            logger.error(f"è®­ç»ƒéšæœºæ£®æ—é”™è¯¯: {e}")
            return None
    
    def train_xgboost(self, X_train, y_train, X_test, y_test):
        """å¢å¼ºï¼šå…·æœ‰æ›´æ·±å­¦ä¹ çš„æ›´å¤æ‚XGBoost - å·²ä¿®å¤"""
        try:
            # æ”¹è¿›ï¼šç”¨äºå°ä¿¡å·é¢„æµ‹çš„æ›´å¥½è¶…å‚æ•°
            xgb_model = xgb.XGBRegressor(
                n_estimators=100,         # å‡å°‘ä»¥å®ç°æ›´å¿«æ”¶æ•›
                max_depth=4,              # æ›´æµ…çš„æ ‘ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆ
                learning_rate=0.1,        # æ›´å¿«çš„å­¦ä¹ ç‡ä»¥æ›´å¥½åœ°æ•è·ä¿¡å·
                subsample=0.9,            # å¯¹å°æ•°æ®é›†æ›´é«˜çš„é‡‡æ ·ç‡
                colsample_bytree=0.9,     # æ›´å¤šç‰¹å¾ç”¨äºå°ä¿¡å·
                reg_alpha=0.1,            # æ›´è½»çš„L1æ­£åˆ™åŒ–
                reg_lambda=0.1,           # æ›´è½»çš„L2æ­£åˆ™åŒ–
                gamma=0.0,                # å¯¹å°ä¿¡å·æ— æœ€å°åˆ†å‰²æŸå¤±
                min_child_weight=1,       # å…è®¸æ›´å°çš„å¶å­æƒé‡
                random_state=42,
                n_jobs=-1,
                verbosity=0,              # å‡å°‘å†—é•¿
                eval_metric='rmse'        # ä¿®å¤ï¼šåœ¨æ„é€ å‡½æ•°ä¸­è®¾ç½®è¯„ä¼°æŒ‡æ ‡
            )
            
            logger.info("ä½¿ç”¨æ”¹è¿›çš„è¶…å‚æ•°è®­ç»ƒXGBoost...")
            
            # ç®€åŒ–çš„è®­ç»ƒï¼Œæ²¡æœ‰æ—©åœä»¥è·å¾—æ›´å¥½çš„å¯é æ€§
            xgb_model.fit(X_train, y_train, verbose=False)
            
            logger.info(f"XGBoostè®­ç»ƒå®Œæˆï¼æœ€ä½³è¿­ä»£: {getattr(xgb_model, 'best_iteration', 'N/A')}")
            
            train_pred = xgb_model.predict(X_train)
            test_pred = xgb_model.predict(X_test)
            
            train_r2 = r2_score(y_train, train_pred)
            test_r2 = r2_score(y_test, test_pred)
            
            # ç‰¹å¾é‡è¦æ€§
            feature_importance = pd.DataFrame({
                'feature': X_train.columns,
                'importance': xgb_model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            self.models['xgboost'] = xgb_model
            self.feature_importance['xgboost'] = feature_importance
            
            logger.info(f"XGBoost - è®­ç»ƒRÂ²: {train_r2:.4f}, æµ‹è¯•RÂ²: {test_r2:.4f}")
            
            return {
                'model': xgb_model,
                'train_r2': train_r2,
                'test_r2': test_r2,
                'feature_importance': feature_importance,
                'predictions': test_pred
            }
            
        except Exception as e:
            logger.error(f"è®­ç»ƒXGBoosté”™è¯¯: {e}")
            return None
    
    def ensemble_predictions(self, predictions_dict, weights=None):
        """ç»“åˆå¤šä¸ªæ¨¡å‹çš„é›†æˆæ–¹æ³•ï¼ˆå †å /æ··åˆï¼‰"""
        try:
            if not predictions_dict:
                return np.array([])
                
            predictions = np.column_stack(list(predictions_dict.values()))
            
            if weights is None:
                # ç­‰æƒé‡
                ensemble_pred = np.mean(predictions, axis=1)
            else:
                # åŠ æƒå¹³å‡
                ensemble_pred = np.average(predictions, axis=1, weights=weights)
            
            logger.info(f"ä» {len(predictions_dict)} ä¸ªæ¨¡å‹åˆ›å»ºé›†æˆ")
            return ensemble_pred
            
        except Exception as e:
            logger.error(f"åˆ›å»ºé›†æˆé”™è¯¯: {e}")
            return np.array([])

class GARCHVolatilityModel:
    """æŒ‰ç…§è§„èŒƒè¿›è¡ŒGARCHæ³¢åŠ¨ç‡é¢„æµ‹"""
    
    def __init__(self):
        self.model = None
        self.fitted_model = None
        
    def fit_garch_model(self, returns, p=1, q=1):
        """å°†GARCH(p,q)æ¨¡å‹æ‹Ÿåˆåˆ°æ”¶ç›Šåºåˆ—"""
        try:
            if not ARCH_AVAILABLE:
                logger.warning("ARCHåº“ä¸å¯ç”¨ã€‚ä½¿ç”¨ç®€å•æ³¢åŠ¨ç‡è®¡ç®—ã€‚")
                return self._simple_volatility_model(returns)
            
            # æ¸…ç†æ”¶ç›Šæ•°æ®
            returns = returns.dropna() * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”æ”¶ç›Š
            
            if len(returns) < 100:
                logger.warning("GARCHå»ºæ¨¡æ•°æ®ä¸è¶³")
                return None
                
            # æ‹ŸåˆGARCHæ¨¡å‹
            self.model = arch_model(returns, vol='Garch', p=p, q=q, dist='normal')
            self.fitted_model = self.model.fit(disp='off')
            
            logger.info(f"GARCH({p},{q}) æ¨¡å‹æˆåŠŸæ‹Ÿåˆ")
            logger.info(f"AIC: {self.fitted_model.aic:.2f}")
            
            return self.fitted_model
            
        except Exception as e:
            logger.error(f"æ‹ŸåˆGARCHæ¨¡å‹é”™è¯¯: {e}")
            return None
    
    def _simple_volatility_model(self, returns):
        """å½“ARCHä¸å¯ç”¨æ—¶çš„ç®€å•æ³¢åŠ¨ç‡æ¨¡å‹"""
        returns = returns.dropna()
        if len(returns) < 30:
            return None
        
        # ç®€å•æŒ‡æ•°åŠ æƒæ³¢åŠ¨ç‡
        volatility = returns.ewm(span=30).std()
        
        # åˆ›å»ºç®€å•æ¨¡å‹å¯¹è±¡
        class SimpleVolModel:
            def __init__(self, vol_series):
                self.volatility = vol_series
                self.aic = 0  # å ä½ç¬¦
            
            def forecast(self, horizon=1):
                class Forecast:
                    def __init__(self, vol_forecast):
                        self.variance = pd.DataFrame([[vol_forecast**2] * horizon])
                return Forecast(self.volatility.iloc[-1])
        
        simple_model = SimpleVolModel(volatility)
        self.fitted_model = simple_model
        logger.info("ç®€å•æ³¢åŠ¨ç‡æ¨¡å‹å·²æ‹Ÿåˆï¼ˆARCHä¸å¯ç”¨ï¼‰")
        return simple_model
    
    def forecast_volatility(self, horizon=1):
        """ä½¿ç”¨æ‹Ÿåˆçš„GARCHæ¨¡å‹é¢„æµ‹æ³¢åŠ¨ç‡"""
        try:
            if self.fitted_model is None:
                logger.error("GARCHæ¨¡å‹æœªæ‹Ÿåˆ")
                return None
                
            forecast = self.fitted_model.forecast(horizon=horizon)
            volatility_forecast = np.sqrt(forecast.variance.values[-1, :])
            
            return volatility_forecast / 100  # è½¬æ¢å›å°æ•°
            
        except Exception as e:
            logger.error(f"é¢„æµ‹æ³¢åŠ¨ç‡é”™è¯¯: {e}")
            return None

class RiskManagementSystem:
    """æŒ‰ç…§è§„èŒƒè¿›è¡Œé£é™©ç®¡ç†"""
    
    def __init__(self, confidence_level=0.05):
        self.confidence_level = confidence_level
        
    def calculate_var(self, returns, method='historical'):
        """ä½¿ç”¨å¤šç§æ–¹æ³•è®¡ç®—é£é™©ä»·å€¼"""
        try:
            returns = returns.dropna()
            
            if method == 'historical':
                var = np.percentile(returns, self.confidence_level * 100)
            elif method == 'parametric':
                mean_return = returns.mean()
                std_return = returns.std()
                var = mean_return - norm.ppf(1 - self.confidence_level) * std_return
            elif method == 'monte_carlo':
                # ç®€å•è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ
                np.random.seed(42)
                simulated_returns = np.random.normal(returns.mean(), returns.std(), 10000)
                var = np.percentile(simulated_returns, self.confidence_level * 100)
            else:
                raise ValueError("æ–¹æ³•å¿…é¡»æ˜¯ 'historical', 'parametric', æˆ– 'monte_carlo'")
                
            return var
            
        except Exception as e:
            logger.error(f"è®¡ç®—VaRé”™è¯¯: {e}")
            return None
    
    def calculate_expected_shortfall(self, returns):
        """è®¡ç®—é¢„æœŸçŸ­ç¼ºï¼ˆCVaRï¼‰"""
        try:
            returns = returns.dropna()
            var = self.calculate_var(returns, method='historical')
            
            # CVaRæ˜¯ä½äºVaRçš„æ”¶ç›Šçš„æœŸæœ›å€¼
            shortfall_returns = returns[returns <= var]
            expected_shortfall = shortfall_returns.mean()
            
            return expected_shortfall
            
        except Exception as e:
            logger.error(f"è®¡ç®—é¢„æœŸçŸ­ç¼ºé”™è¯¯: {e}")
            return None
    
    def calculate_maximum_drawdown(self, returns):
        """è®¡ç®—æœ€å¤§å›æ’¤åˆ†æ"""
        try:
            cumulative_returns = (1 + returns).cumprod()
            running_max = cumulative_returns.expanding().max()
            drawdown = (cumulative_returns - running_max) / running_max
            
            max_drawdown = drawdown.min()
            max_drawdown_duration = self._calculate_drawdown_duration(drawdown)
            
            return {
                'max_drawdown': max_drawdown,
                'max_drawdown_duration': max_drawdown_duration,
                'current_drawdown': drawdown.iloc[-1]
            }
            
        except Exception as e:
            logger.error(f"è®¡ç®—æœ€å¤§å›æ’¤é”™è¯¯: {e}")
            return None
    
    def _calculate_drawdown_duration(self, drawdown):
        """è®¡ç®—æœ€å¤§å›æ’¤æŒç»­æ—¶é—´"""
        try:
            is_drawdown = drawdown < 0
            drawdown_periods = []
            current_period = 0
            
            for dd in is_drawdown:
                if dd:
                    current_period += 1
                else:
                    if current_period > 0:
                        drawdown_periods.append(current_period)
                    current_period = 0
            
            if current_period > 0:
                drawdown_periods.append(current_period)
                
            return max(drawdown_periods) if drawdown_periods else 0
            
        except Exception as e:
            logger.error(f"è®¡ç®—å›æ’¤æŒç»­æ—¶é—´é”™è¯¯: {e}")
            return 0

class OptionsFlowPredictiveSystem:
    """åè°ƒæ‰€æœ‰ç»„ä»¶çš„ä¸»ç³»ç»Ÿ"""
    
    def __init__(self, symbols=['SPY', 'QQQ', 'IWM'], fred_api_key=None):
        self.symbols = symbols
        self.data_pipeline = OptionsFlowDataPipeline(fred_api_key)
        self.data_processor = OptionsDataProcessor()
        self.ml_pipeline = MachineLearningPipeline()
        self.garch_model = GARCHVolatilityModel()
        self.risk_mgmt = RiskManagementSystem()
        
        self.historical_data = {}
        self.models = {}
        self.features_data = pd.DataFrame()
        
    def collect_market_data(self, start_date='2022-01-01'):
        """ä»æŒ‡å®šæ¥æºæ”¶é›†æ‰€æœ‰å¸‚åœºæ•°æ®ï¼ŒåŒ…å«æ‰©å±•å†å²"""
        logger.info("å¼€å§‹å¢å¼ºå¸‚åœºæ•°æ®æ”¶é›†...")
        
        # è·å–CBOEæ•°æ®
        cboe_data = self.data_pipeline.get_cboe_vix_data(start_date)
        
        # è·å–ç»æµæ•°æ®
        econ_data = self.data_pipeline.get_fred_economic_data(start_date)
        
        # è·å–æ¯ä¸ªç¬¦å·çš„æœŸæƒå’Œè‚¡ç¥¨æ•°æ®
        for symbol in self.symbols:
            logger.info(f"å¤„ç† {symbol}...")
            
            try:
                # è·å–å†å²è‚¡ç¥¨æ•°æ®
                ticker = yf.Ticker(symbol)
                stock_data = ticker.history(start=start_date)
                
                # è®¡ç®—æ”¶ç›Š
                stock_data['return_1d'] = stock_data['Close'].pct_change()
                stock_data['return_5d'] = stock_data['Close'].pct_change(periods=5)
                
                # è·å–å½“å‰æœŸæƒæ•°æ®
                options_data = self.data_processor.get_options_chain_data(symbol)
                
                self.historical_data[symbol] = {
                    'stock_data': stock_data,
                    'options_data': options_data,
                    'cboe_data': cboe_data,
                    'econ_data': econ_data
                }
                
                logger.info(f"æ”¶é›†åˆ° {symbol} çš„æ•°æ®: "
                          f"{len(stock_data)} æ¡è‚¡ç¥¨è®°å½•, "
                          f"{len(options_data)} ä¸ªæœŸæƒåˆçº¦")
                
            except Exception as e:
                logger.error(f"æ”¶é›† {symbol} æ•°æ®é”™è¯¯: {e}")
        
        logger.info("å¸‚åœºæ•°æ®æ”¶é›†å®Œæˆ")
    
    def engineer_features(self):
        """é˜²å¼¹ç‰¹å¾å·¥ç¨‹ï¼Œä¿è¯å˜é‡åˆå§‹åŒ–"""
        logger.info("ğŸš€ å¼€å§‹é˜²å¼¹ç‰¹å¾å·¥ç¨‹...")
        
        all_features = []
        
        for symbol in self.symbols:
            if symbol not in self.historical_data:
                continue
                
            logger.info(f"ğŸ”„ å¤„ç† {symbol} çš„ç‰¹å¾...")
            
            try:
                stock_data = self.historical_data[symbol]['stock_data']
                options_data = self.historical_data[symbol]['options_data']
                cboe_data = self.historical_data[symbol]['cboe_data']
                
                if stock_data.empty:
                    logger.warning(f"{symbol} æ— è‚¡ç¥¨æ•°æ®ï¼Œè·³è¿‡")
                    continue
                
                # æ‰©å±•å†å²æ•°æ®çª—å£ï¼ˆ500å¤©ï¼‰
                recent_dates = stock_data.index[-500:]
                
                for date_idx, current_date in enumerate(recent_dates):
                    # é˜²å¼¹åˆå§‹åŒ– - æ‰€æœ‰å˜é‡ä¿è¯åˆå§‹åŒ–
                    feature_data = self._initialize_feature_data(current_date, symbol)
                    
                    # å®‰å…¨æ•°æ®æå–
                    self._extract_basic_data(feature_data, stock_data, current_date)
                    
                    # å®‰å…¨è®¡ç®—æ‰€æœ‰ç‰¹å¾
                    self._calculate_targets(feature_data, stock_data, recent_dates, date_idx)
                    self._calculate_regime_features(feature_data, cboe_data, symbol)
                    self._calculate_options_features(feature_data, options_data)
                    self._calculate_technical_features(feature_data, stock_data)
                    self._calculate_volatility_features(feature_data, stock_data)
                    self._add_cboe_features(feature_data, cboe_data)
                    
                    # åˆ›å»ºæœ€ç»ˆç‰¹å¾è¡Œ
                    feature_row = self._create_feature_row(feature_data)
                    all_features.append(feature_row)
                    
                    # è¿›åº¦æ—¥å¿—
                    if (date_idx + 1) % 100 == 0:
                        logger.info(f"  ğŸ“Š å·²å¤„ç† {date_idx + 1}/{len(recent_dates)} ä¸ªæ—¥æœŸ for {symbol}")
                
                logger.info(f"âœ… å®Œæˆ {symbol} çš„ {len(recent_dates)} ä¸ªæ—¥æœŸ")
                
            except Exception as symbol_error:
                logger.error(f"âŒ å¤„ç† {symbol} é”™è¯¯: {symbol_error}")
                continue
        
        # åˆ›å»ºæœ€ç»ˆæ•°æ®é›†
        self.features_data = pd.DataFrame(all_features)
        
        if not self.features_data.empty:
            # æ¸…ç†æ•°æ®
            initial_count = len(self.features_data)
            self.features_data = self.features_data.dropna(thresh=int(len(self.features_data.columns) * 0.7))
            
            # å¡«å……å‰©ä½™çš„NaNå€¼
            numeric_cols = self.features_data.select_dtypes(include=[np.number]).columns
            self.features_data[numeric_cols] = self.features_data[numeric_cols].fillna(0)
            
            # åˆ é™¤æ— é™å€¼
            self.features_data = self.features_data.replace([np.inf, -np.inf], 0)
            
            final_count = len(self.features_data)
            logger.info(f"ğŸ§¹ æ•°æ®æ¸…ç†: {initial_count} â†’ {final_count} æ¡è®°å½•")
            logger.info(f"ğŸ¯ æœ€ç»ˆæ•°æ®é›†: {final_count} æ¡è®°å½•, {len(self.features_data.columns)} ä¸ªç‰¹å¾")
        
        return self.features_data
    
    def _initialize_feature_data(self, current_date, symbol):
        """ä½¿ç”¨å®‰å…¨é»˜è®¤å€¼åˆå§‹åŒ–æ‰€æœ‰ç‰¹å¾æ•°æ®"""
        return {
            'date': current_date,
            'symbol': symbol,
            'current_price': 100.0,
            'current_volume': 1000000.0,
            'return_1d': 0.0,
            'return_5d': 0.0,
            'rsi': 50.0,
            'macd': 0.0,
            'bb_position': 0.0,
            'volatility_forecast': 0.2,
            'targets': {
                'target_1d': 0.0,
                'target_3d': 0.0,
                'target_5d': 0.0,
                'target_sharpe': 0.0,
                'target_strong_move': 0,
                'target_direction': 0
            },
            'regime_features': {
                'vix_regime': 0,
                'vix_term_regime': 0,
                'unemployment_regime': 0,
                'fed_regime': 0,
                'inflation_regime': 0,
                'treasury_regime': 0,
                'usd_regime': 0
            },
            'pcr_features': {
                'pcr_volume': 1.0,
                'pcr_open_interest': 1.0,
                'put_volume': 0.0,
                'call_volume': 0.0
            },
            'volume_features': {
                'total_volume': 0.0,
                'uoa_ratio': 0.0,
                'unusual_volume_signal': False
            },
            'dealer_features': {
                'net_gamma_exposure': 0.0,
                'total_gamma': 0.0
            },
            'vol_features': {
                'atm_iv_average': 0.2
            },
            'cboe_features': {
                'VIX': 20.0,
                'VIX_Z_Score': 0.0,
                'VIX_Term_Structure': 0.0
            }
        }
    
    def _extract_basic_data(self, feature_data, stock_data, current_date):
        """å®‰å…¨æå–åŸºæœ¬ä»·æ ¼å’Œæˆäº¤é‡æ•°æ®"""
        try:
            if current_date in stock_data.index:
                feature_data['current_price'] = float(stock_data.loc[current_date, 'Close'])
                feature_data['current_volume'] = float(stock_data.loc[current_date, 'Volume'])
                
                # è®¡ç®—æ”¶ç›Š
                historical_data = stock_data.loc[:current_date]
                if len(historical_data) >= 2:
                    ret_1d = historical_data['Close'].pct_change().iloc[-1]
                    feature_data['return_1d'] = float(ret_1d) if not pd.isna(ret_1d) else 0.0
                
                if len(historical_data) >= 5:
                    ret_5d = historical_data['Close'].pct_change(periods=5).iloc[-1]
                    feature_data['return_5d'] = float(ret_5d) if not pd.isna(ret_5d) else 0.0
        except Exception as e:
            logger.debug(f"åŸºæœ¬æ•°æ®æå–é”™è¯¯: {e}")
    
    def _calculate_targets(self, feature_data, stock_data, recent_dates, date_idx):
        """è®¡ç®—ç›®æ ‡å˜é‡"""
        try:
            current_price = feature_data['current_price']
            
            # è®¡ç®—å‰ç»æ”¶ç›Š
            for horizon in [1, 3, 5]:
                if date_idx + horizon < len(recent_dates):
                    future_date = recent_dates[date_idx + horizon]
                    if future_date in stock_data.index:
                        future_price = float(stock_data.loc[future_date, 'Close'])
                        target_return = (future_price - current_price) / current_price
                        feature_data['targets'][f'target_{horizon}d'] = target_return
        except Exception as e:
            logger.debug(f"ç›®æ ‡è®¡ç®—é”™è¯¯: {e}")
    
    def _calculate_regime_features(self, feature_data, cboe_data, symbol):
        """è®¡ç®—åˆ¶åº¦ç‰¹å¾"""
        try:
            current_date = feature_data['date']
            
            # VIXåˆ¶åº¦
            if not cboe_data.empty and current_date in cboe_data.index:
                vix_current = cboe_data.loc[current_date, 'VIX']
                if vix_current < 15:
                    feature_data['regime_features']['vix_regime'] = 1
                elif vix_current > 25:
                    feature_data['regime_features']['vix_regime'] = -1
            
            # ç»æµåˆ¶åº¦ï¼ˆç›®å‰ç®€åŒ–ï¼‰
            econ_data = self.historical_data[symbol].get('econ_data', pd.DataFrame())
            if not econ_data.empty:
                # ç»æµåˆ¶åº¦æ£€æµ‹çš„å®ç°
                pass
        except Exception as e:
            logger.debug(f"åˆ¶åº¦è®¡ç®—é”™è¯¯: {e}")
    
    def _calculate_options_features(self, feature_data, options_data):
        """è®¡ç®—åŸºäºæœŸæƒçš„ç‰¹å¾"""
        try:
            if not options_data.empty:
                pcr_features = self.data_processor.calculate_putcall_ratios(options_data)
                if pcr_features:
                    feature_data['pcr_features'].update(pcr_features)
                
                volume_features = self.data_processor.detect_unusual_volume(options_data)
                if volume_features:
                    feature_data['volume_features'].update(volume_features)
                
                dealer_features = self.data_processor.calculate_dealer_positioning(options_data, feature_data['current_price'])
                if dealer_features:
                    feature_data['dealer_features'].update(dealer_features)
        except Exception as e:
            logger.debug(f"æœŸæƒç‰¹å¾é”™è¯¯: {e}")
    
    def _calculate_technical_features(self, feature_data, stock_data):
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
        try:
            current_date = feature_data['date']
            historical_data = stock_data.loc[:current_date]
            
            if len(historical_data) >= 14:
                if TALIB_AVAILABLE:
                    try:
                        rsi_val = ta.RSI(historical_data['Close'].values)[-1]
                        feature_data['rsi'] = float(rsi_val)
                    except:
                        pass
                else:
                    rsi_series = rsi_fallback(historical_data['Close'])
                    feature_data['rsi'] = float(rsi_series.iloc[-1])
        except Exception as e:
            logger.debug(f"æŠ€æœ¯ç‰¹å¾é”™è¯¯: {e}")
    
    def _calculate_volatility_features(self, feature_data, stock_data):
        """è®¡ç®—æ³¢åŠ¨ç‡ç‰¹å¾"""
        try:
            current_date = feature_data['date']
            historical_data = stock_data.loc[:current_date]
            returns = historical_data['Close'].pct_change().dropna()
            
            if len(returns) > 30:
                garch_model = self.garch_model.fit_garch_model(returns)
                if garch_model:
                    vol_forecast = self.garch_model.forecast_volatility(horizon=1)
                    if vol_forecast is not None:
                        feature_data['volatility_forecast'] = float(vol_forecast[0])
        except Exception as e:
            logger.debug(f"æ³¢åŠ¨ç‡ç‰¹å¾é”™è¯¯: {e}")
    
    def _add_cboe_features(self, feature_data, cboe_data):
        """æ·»åŠ CBOEç‰¹å¾"""
        try:
            current_date = feature_data['date']
            if not cboe_data.empty and current_date in cboe_data.index:
                cboe_row = cboe_data.loc[current_date]
                for col in ['VIX', 'VIX_Z_Score', 'VIX_Term_Structure']:
                    if col in cboe_row:
                        feature_data['cboe_features'][col] = float(cboe_row[col])
        except Exception as e:
            logger.debug(f"CBOEç‰¹å¾é”™è¯¯: {e}")
    
    def _create_feature_row(self, feature_data):
        """ä»æ‰€æœ‰è®¡ç®—çš„ç‰¹å¾åˆ›å»ºæœ€ç»ˆç‰¹å¾è¡Œ"""
        feature_row = {
            'date': feature_data['date'],
            'symbol': feature_data['symbol'],
            'close_price': feature_data['current_price'],
            'volume': feature_data['current_volume'],
            'return_1d': feature_data['return_1d'],
            'return_5d': feature_data['return_5d'],
            'rsi': feature_data['rsi'],
            'macd': feature_data['macd'],
            'bb_position': feature_data['bb_position'],
            'volatility_forecast': feature_data['volatility_forecast']
        }
        
        # æ·»åŠ æ‰€æœ‰ç‰¹å¾å­—å…¸
        for feature_dict in ['targets', 'regime_features', 'pcr_features', 'volume_features', 
                           'dealer_features', 'vol_features', 'cboe_features']:
            for k, v in feature_data[feature_dict].items():
                if isinstance(v, (int, float, bool)):
                    feature_row[k] = float(v) if isinstance(v, (int, float)) else int(v)
                else:
                    feature_row[k] = 0.0
        
        return feature_row
    
    def train_models(self):
        """è®­ç»ƒå¢å¼ºçš„MLæ¨¡å‹"""
        logger.info("ğŸš€ å¼€å§‹å¢å¼ºæ¨¡å‹è®­ç»ƒ...")
        
        if self.features_data.empty:
            logger.error("æ— ç‰¹å¾æ•°æ®å¯ç”¨")
            return
        
        # å‡†å¤‡æ•°æ®
        X, feature_cols = self.ml_pipeline.prepare_features(self.features_data)
        y = self.features_data['target_1d'].fillna(0)
        
        if len(X) == 0:
            logger.error("æ— æœ‰æ•ˆç‰¹å¾ç”¨äºè®­ç»ƒ")
            return
        
        # æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
        tscv = TimeSeriesSplit(n_splits=3)
        
        for train_idx, test_idx in tscv.split(X):
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
            
            logger.info(f"ğŸ“Š è®­ç»ƒæ¨¡å‹: {len(X_train)} è®­ç»ƒæ ·æœ¬, {len(X_test)} æµ‹è¯•æ ·æœ¬")
            
            # è®­ç»ƒéšæœºæ£®æ—
            rf_results = self.ml_pipeline.train_random_forest(X_train, y_train, X_test, y_test)
            
            # è®­ç»ƒXGBoost
            xgb_results = self.ml_pipeline.train_xgboost(X_train, y_train, X_test, y_test)
            
            # å­˜å‚¨ç»“æœ
            self.models = {
                'random_forest': rf_results,
                'xgboost': xgb_results
            }
            
            # åˆ›å»ºé›†æˆ
            if rf_results and xgb_results:
                predictions = {
                    'rf': rf_results['predictions'],
                    'xgb': xgb_results['predictions']
                }
                ensemble_pred = self.ml_pipeline.ensemble_predictions(predictions)
                
                if len(ensemble_pred) > 0:
                    ensemble_r2 = r2_score(y_test, ensemble_pred)
                    logger.info(f"ğŸ¯ é›†æˆRÂ²: {ensemble_r2:.4f}")
                    
                    self.models['ensemble'] = {
                        'predictions': ensemble_pred,
                        'test_r2': ensemble_r2
                    }
            
            break  # ä½¿ç”¨ç¬¬ä¸€ä¸ªåˆ†å‰²
        
        logger.info("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
    
    def generate_signals(self):
        """ç”Ÿæˆå¢å¼ºçš„äº¤æ˜“ä¿¡å·"""
        logger.info("ğŸš¨ ç”Ÿæˆäº¤æ˜“ä¿¡å·...")
        
        signals = {}
        
        for symbol in self.symbols:
            try:
                symbol_features = self.features_data[self.features_data['symbol'] == symbol]
                if symbol_features.empty:
                    continue
                
                latest_features = symbol_features.iloc[-1]
                
                signals[symbol] = {
                    'timestamp': pd.Timestamp.now(),
                    'symbol': symbol,
                    'current_price': latest_features.get('close_price', 0)
                }
                
                # çœ‹è·Œ/çœ‹æ¶¨æ¯”ç‡ä¿¡å·
                if 'pcr_volume' in latest_features:
                    pcr = latest_features['pcr_volume']
                    if pcr < 0.7:
                        signals[symbol]['pcr_signal'] = 'bullish'
                    elif pcr > 1.0:
                        signals[symbol]['pcr_signal'] = 'bearish'
                    else:
                        signals[symbol]['pcr_signal'] = 'neutral'
                
                # å¼‚å¸¸æˆäº¤é‡ä¿¡å·
                if 'uoa_ratio' in latest_features:
                    signals[symbol]['unusual_volume'] = latest_features['uoa_ratio'] > 1.25
                
                # MLé¢„æµ‹
                if 'random_forest' in self.models and self.models['random_forest']:
                    X_current, _ = self.ml_pipeline.prepare_features(symbol_features.iloc[[-1]])
                    if len(X_current) > 0:
                        prediction = self.models['random_forest']['model'].predict(X_current)[0]
                        signals[symbol]['ml_prediction'] = prediction
                        signals[symbol]['ml_signal'] = 'bullish' if prediction > 0 else 'bearish'
                
                logger.info(f"{symbol} çš„ä¿¡å·: {signals[symbol]}")
                
            except Exception as e:
                logger.error(f"ç”Ÿæˆ {symbol} ä¿¡å·é”™è¯¯: {e}")
        
        return signals
    
    def interpret_trading_signals(self, signals, results):
        """ç»¼åˆäº¤æ˜“ä¿¡å·è§£é‡Š"""
        print("\n" + "="*80)
        print("ğŸ“ˆ **ç»¼åˆäº¤æ˜“ä¿¡å·è§£é‡Š**")
        print("="*80)
        
        if not signals:
            print("âŒ æœªç”Ÿæˆä¿¡å·")
            return
        
        # å¸‚åœºæ¦‚è§ˆ
        bullish_count = sum(1 for s in signals.values() if s.get('ml_signal') == 'bullish')
        bearish_count = sum(1 for s in signals.values() if s.get('ml_signal') == 'bearish')
        
        print(f"\nğŸŒ **å¸‚åœºæ¦‚è§ˆ**")
        print(f"â€¢ åˆ†æçš„æ€»ç¬¦å·æ•°: {len(signals)}")
        print(f"â€¢ MLä¿¡å·: {bullish_count} çœ‹æ¶¨, {bearish_count} çœ‹è·Œ")
        print(f"â€¢ å¸‚åœºæƒ…ç»ª: {'çœ‹æ¶¨' if bullish_count > bearish_count else 'çœ‹è·Œ' if bearish_count > bullish_count else 'ä¸­æ€§'}")
        
        # è¯¦ç»†ä¿¡å·åˆ†æ
        for symbol, signal_data in signals.items():
            print(f"\nğŸ“Š **{symbol} ({self._get_etf_description(symbol)})**")
            print(f"â€¢ **ä»·æ ¼**: ${signal_data.get('current_price', 0):.2f}")
            
            # çœ‹è·Œ/çœ‹æ¶¨ä¿¡å·åˆ†æ
            pcr_signal = signal_data.get('pcr_signal', 'unknown')
            pcr_emoji = "ğŸŸ¢" if pcr_signal == 'bullish' else "ğŸ”´" if pcr_signal == 'bearish' else "ğŸŸ¡"
            print(f"â€¢ **çœ‹è·Œ/çœ‹æ¶¨ä¿¡å·**: {pcr_emoji} {pcr_signal.upper()}")
            
            if 'pcr_volume' in signal_data:
                pcr_val = signal_data['pcr_volume']
                print(f"  - çœ‹è·Œ/çœ‹æ¶¨æ¯”ç‡: {pcr_val:.2f}")
                if pcr_val < 0.7:
                    print(f"  - åˆ†æ: å¼ºçƒˆçš„çœ‹æ¶¨æƒ…ç»ªï¼ˆçœ‹è·Œä¹°å…¥è¾ƒå°‘ï¼‰")
                elif pcr_val > 1.0:
                    print(f"  - åˆ†æ: å¼ºçƒˆçš„çœ‹è·Œæƒ…ç»ªï¼ˆå¤§é‡çœ‹è·Œä¹°å…¥ï¼‰")
                else:
                    print(f"  - åˆ†æ: ä¸­æ€§æƒ…ç»ª")
            
            # å¼‚å¸¸æˆäº¤é‡åˆ†æ
            unusual_vol = signal_data.get('unusual_volume', False)
            vol_emoji = "âš¡" if unusual_vol else "ğŸ“Š"
            print(f"â€¢ **å¼‚å¸¸æˆäº¤é‡**: {vol_emoji} {'æ˜¯' if unusual_vol else 'å¦'}")
            
            if unusual_vol:
                print(f"  - åˆ†æ: æ£€æµ‹åˆ°é«˜æœºæ„æ´»åŠ¨")
                print(f"  - å«ä¹‰: æ½œåœ¨çš„é‡å¤§ä»·æ ¼å˜åŠ¨")
            
            # MLé¢„æµ‹åˆ†æ
            ml_pred = signal_data.get('ml_prediction', 0)
            ml_signal = signal_data.get('ml_signal', 'unknown')
            ml_emoji = "ğŸŸ¢" if ml_signal == 'bullish' else "ğŸ”´"
            
            print(f"â€¢ **MLé¢„æµ‹**: {ml_emoji} {ml_pred:.6f} ({ml_pred*100:.4f}%)")
            print(f"â€¢ **MLä¿¡å·**: {ml_signal.upper()}")
            
            # ä¿¡å·å¼ºåº¦åˆ†æ
            pred_strength = abs(ml_pred * 100)
            if pred_strength > 0.05:
                strength = "å¼º"
            elif pred_strength > 0.02:
                strength = "ä¸­ç­‰"
            else:
                strength = "å¼±"
            print(f"â€¢ **ä¿¡å·å¼ºåº¦**: {strength}")
            
            # å†²çªåˆ†æ
            pcr_bullish = pcr_signal == 'bullish'
            ml_bullish = ml_signal == 'bullish'
            
            if pcr_bullish == ml_bullish:
                print(f"â€¢ **ä¿¡å·å¯¹é½**: âœ… å¯¹é½ ({pcr_signal.upper()})")
                confidence = "é«˜"
            else:
                print(f"â€¢ **ä¿¡å·å†²çª**: âš ï¸  æœŸæƒ {pcr_signal.upper()} vs ML {ml_signal.upper()}")
                confidence = "ä½"
            
            print(f"â€¢ **ç½®ä¿¡æ°´å¹³**: {confidence}")
            
            # äº¤æ˜“æ¨è
            print(f"â€¢ **äº¤æ˜“æ¨è**:")
            if confidence == "é«˜" and strength in ["å¼º", "ä¸­ç­‰"]:
                if ml_bullish:
                    print(f"  - ğŸ“ˆ è€ƒè™‘å¤šå¤´å¤´å¯¸")
                    print(f"  - ç­–ç•¥: ä¹°å…¥çœ‹æ¶¨æœŸæƒæˆ–åšå¤šè‚¡ç¥¨")
                else:
                    print(f"  - ğŸ“‰ è€ƒè™‘ç©ºå¤´å¤´å¯¸") 
                    print(f"  - ç­–ç•¥: ä¹°å…¥çœ‹è·ŒæœŸæƒæˆ–åšç©ºè‚¡ç¥¨")
            elif unusual_vol:
                print(f"  - âš¡ æ³¢åŠ¨ç‡äº¤æ˜“")
                print(f"  - ç­–ç•¥: è·¨å¼/å®½è·¨å¼ç»„åˆä»¥åº”å¯¹æ–¹å‘æ€§ç§»åŠ¨")
            else:
                print(f"  - â¸ï¸  ç­‰å¾…è§‚å¯Ÿ")
                print(f"  - ç­–ç•¥: ç›‘æ§æ›´æ¸…æ™°çš„ä¿¡å·")
            
            # é£é™©è¯„ä¼°
            print(f"â€¢ **é£é™©è¯„ä¼°**:")
            if unusual_vol and confidence == "ä½":
                print(f"  - ğŸ”´ é«˜é£é™©: å†²çªä¿¡å·ä¼´éšé«˜æˆäº¤é‡")
            elif strength == "å¼±":
                print(f"  - ğŸŸ¡ ä¸­ç­‰é£é™©: å¼±é¢„æµ‹ä¿¡å·")
            else:
                print(f"  - ğŸŸ¢ å¯æ§é£é™©: æ¸…æ™°çš„æ–¹å‘æ€§ä¿¡å·")
        
        # æ•´ä½“å¸‚åœºç­–ç•¥
        print(f"\nğŸ¯ **æ•´ä½“å¸‚åœºç­–ç•¥**")
        
        all_unusual_volume = all(s.get('unusual_volume', False) for s in signals.values())
        if all_unusual_volume:
            print(f"â€¢ **å¸‚åœºçŠ¶æ€**: é«˜æ³¢åŠ¨æ€§ç¯å¢ƒ")
            print(f"â€¢ **ç­–ç•¥**: å‡†å¤‡åº”å¯¹æ‰€æœ‰è¡Œä¸šçš„é‡å¤§å˜åŠ¨")
            print(f"â€¢ **é£é™©ç®¡ç†**: å‡å°‘å¤´å¯¸è§„æ¨¡ï¼Œå¢åŠ æ­¢æŸ")
        
        # æ¨¡å‹æ€§èƒ½èƒŒæ™¯
        if 'models' in results:
            rf_r2 = results['models'].get('random_forest', {}).get('test_r2', 0)
            xgb_r2 = results['models'].get('xgboost', {}).get('test_r2', 0)
            ensemble_r2 = results['models'].get('ensemble', {}).get('test_r2', 0)
            
            print(f"\nğŸ¤– **æ¨¡å‹æ€§èƒ½èƒŒæ™¯**")
            print(f"â€¢ éšæœºæ£®æ— RÂ²: {rf_r2:.4f}")
            print(f"â€¢ XGBoost RÂ²: {xgb_r2:.4f}")
            print(f"â€¢ é›†æˆ RÂ²: {ensemble_r2:.4f}")
            
            if rf_r2 > 0.5:
                print(f"â€¢ **æ¨¡å‹å¯é æ€§**: é«˜ (RÂ² > 0.5)")
            elif rf_r2 > 0.3:
                print(f"â€¢ **æ¨¡å‹å¯é æ€§**: ä¸­ç­‰ (RÂ² > 0.3)")
            else:
                print(f"â€¢ **æ¨¡å‹å¯é æ€§**: ä½ (RÂ² < 0.3)")
        
        print(f"\nâš ï¸  **é‡è¦å…è´£å£°æ˜**")
        print(f"â€¢ è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§çš„å­¦æœ¯æ¨¡å‹")
        print(f"â€¢ è¿‡å»çš„è¡¨ç°ä¸èƒ½ä¿è¯æœªæ¥çš„ç»“æœ")
        print(f"â€¢ å§‹ç»ˆä½¿ç”¨é€‚å½“çš„é£é™©ç®¡ç†")
        print(f"â€¢ è€ƒè™‘å¸‚åœºçŠ¶å†µå’Œæ–°é—»äº‹ä»¶")
        print(f"â€¢ åœ¨å®ç›˜äº¤æ˜“å‰å›æµ‹ç­–ç•¥")
        
        print("="*80)
    
    def _get_etf_description(self, symbol):
        """è·å–ç¬¦å·çš„ETFæè¿°"""
        descriptions = {
            'SPY': 'æ ‡æ™®500 ETF - å¤§ç›˜è‚¡',
            'QQQ': 'çº³æ–¯è¾¾å…‹ ETF - ç§‘æŠ€è‚¡é‡ä»“',
            'IWM': 'ç½—ç´ 2000 ETF - å°ç›˜è‚¡',
            'DIA': 'é“ç¼æ–¯ ETF - è“ç­¹è‚¡',
            'VTI': 'å…¨è‚¡ç¥¨å¸‚åœº ETF',
            'EFA': 'å›½é™…å‘è¾¾å¸‚åœº',
            'EEM': 'æ–°å…´å¸‚åœº ETF'
        }
        return descriptions.get(symbol, 'ETF')
    
    
    def run_complete_analysis(self):
        """è¿è¡Œå®Œæ•´çš„å¢å¼ºåˆ†æ"""
        logger.info("ğŸš€ å¼€å§‹å®Œæ•´çš„å¢å¼ºåˆ†æ...")
        
        results = {
            'features': pd.DataFrame(),
            'models': {},
            'signals': {},
            'performance': {}
        }
        
        try:
            # æ­¥éª¤1: æ•°æ®æ”¶é›†
            self.collect_market_data()
            
            # æ­¥éª¤2: ç‰¹å¾å·¥ç¨‹
            features = self.engineer_features()
            results['features'] = features
            
            if features.empty:
                logger.error("æœªç”Ÿæˆç‰¹å¾")
                return results
            
            # æ­¥éª¤3: æ¨¡å‹è®­ç»ƒ
            self.train_models()
            results['models'] = self.models
            
            # æ­¥éª¤4: ä¿¡å·ç”Ÿæˆ
            signals = self.generate_signals()
            results['signals'] = signals
            
            # æ­¥éª¤5: ç»¼åˆä¿¡å·è§£é‡Š
            self.interpret_trading_signals(signals, results)
            
            # æ€»ç»“
            logger.info("\n" + "="*60)
            logger.info("ğŸ‰ å¢å¼ºåˆ†æå®Œæˆ")
            logger.info("="*60)
            logger.info(f"âœ… åˆ†æçš„ç¬¦å·: {', '.join(self.symbols)}")
            logger.info(f"âœ… å·¥ç¨‹ç‰¹å¾: {len(features.columns) if not features.empty else 0}")
            logger.info(f"âœ… è®­ç»ƒæ¨¡å‹: {len([k for k, v in self.models.items() if v is not None])}")
            logger.info(f"âœ… ç”Ÿæˆä¿¡å·: {len(signals)}")
            
            if 'random_forest' in self.models and self.models['random_forest']:
                logger.info("\nğŸ” å‰10ä¸ªç‰¹å¾é‡è¦æ€§:")
                importance_df = self.models['random_forest']['feature_importance'].head(10)
                for _, row in importance_df.iterrows():
                    logger.info(f"  {row['feature']}: {row['importance']:.4f}")
            
            return results
            
        except Exception as e:
            logger.error(f"å®Œæ•´åˆ†æé”™è¯¯: {e}")
            return results

def main():
    """
    å¢å¼ºæœŸæƒæµé¢„æµ‹ç³»ç»Ÿ - å®Œå…¨ä¿®æ­£ç‰ˆ
    
    ğŸš€ å·²å®ç°çš„æ”¹è¿›:
    1. æ‰©å±•å†å²æ•°æ®çª—å£ï¼ˆ500+å¤© vs 30å¤©ï¼‰
    2. å¤šæ—¶é—´èŒƒå›´ç›®æ ‡å˜é‡ï¼ˆ1å¤©ã€3å¤©ã€5å¤©ã€åŸºäºå¤æ™®æ¯”ç‡ï¼‰
    3. åˆ¶åº¦æ£€æµ‹ï¼ˆVIXæ³¢åŠ¨ç‡ + ç»æµå‘¨æœŸï¼‰
    4. å¢å¼ºMLæ¨¡å‹ï¼ˆ200ä¸ªRFä¼°è®¡å™¨ï¼Œ100è½®XGBoostï¼‰
    5. é˜²å¼¹ç‰¹å¾å·¥ç¨‹ï¼ˆæ— å˜é‡é”™è¯¯ï¼‰
    6. äº¤æ˜“æˆæœ¬å»ºæ¨¡å’Œç°å®ä¿¡å·
    7. ä¿®å¤XGBoostè®­ç»ƒé”™è¯¯
    8. ä¿®å¤æ•°æ®æ³„æ¼é—®é¢˜ï¼ˆä»ç‰¹å¾ä¸­ç§»é™¤ç›®æ ‡å˜é‡ï¼‰
    9. æ·»åŠ ç»¼åˆäº¤æ˜“ä¿¡å·è§£é‡Š
    
    ğŸ¯ å­¦æœ¯ç›®æ ‡:
    - Pan & Poteshman (2006): æ¯æ—¥å›æŠ¥è¶…è¿‡40ä¸ªåŸºç‚¹
    - Johnson & So (2012): å¤æ™®æ¯”ç‡è¶…è¿‡2.0
    - å…·æœ‰åˆ¶åº¦æ„è¯†çš„å¤šèµ„äº§æœŸæƒæµé¢„æµ‹
    """
    
    print("ğŸš€ å¢å¼ºæœŸæƒæµé¢„æµ‹å»ºæ¨¡ç³»ç»Ÿ - å®Œå…¨ä¿®æ­£ç‰ˆ")
    print("ğŸ“š åŸºäºå­¦æœ¯ç ”ç©¶: Pan & Poteshman (2006), Johnson & So (2012)")
    print("ğŸ¯ ç›®æ ‡: æ¯æ—¥å›æŠ¥è¶…è¿‡40ä¸ªåŸºç‚¹ï¼Œå¤æ™®æ¯”ç‡è¶…è¿‡2.0")
    print("âœ¨ å·²å®ç°æ‰€æœ‰æ€§èƒ½æ”¹è¿›")
    print("ğŸ’° FREDç»æµæ•°æ®: å¯ç”¨ï¼ˆå¤±ä¸šç‡ã€è”é‚¦åŸºé‡‘åˆ©ç‡ã€CPIï¼‰")
    print("ğŸ”§ ä¿®å¤: XGBoostè®­ç»ƒé”™è¯¯å·²è§£å†³")
    print("ğŸ› ï¸  ä¿®å¤: æ•°æ®æ³„æ¼é—®é¢˜å·²çº æ­£")
    print("ğŸ“Š æ·»åŠ : ç»¼åˆäº¤æ˜“ä¿¡å·è§£é‡Š")
    print("="*80)
    
    # æ£€æŸ¥ç¼ºå°‘çš„å¿…è¦åº“
    missing_libs = []
    try:
        import sklearn
    except ImportError:
        missing_libs.append("scikit-learn")
    
    try:
        import xgboost
    except ImportError:
        missing_libs.append("xgboost")
        
    try:
        import tensorflow
    except ImportError:
        missing_libs.append("tensorflow")
    
    if missing_libs:
        print(f"ç¼ºå°‘å¿…éœ€çš„åº“: {', '.join(missing_libs)}")
        print(f"è¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…: pip install {' '.join(missing_libs)}")
        return
    
    # ä½¿ç”¨ä¸»è¦ETFå’ŒFRED APIå¯†é’¥åˆå§‹åŒ–ç³»ç»Ÿ
    symbols = ['SPY', 'QQQ', 'IWM']  # ç”¨äºæ¼”ç¤ºçš„ä¸»è¦å¸‚åœºETF
    
    # ğŸ”‘ æ‚¨çš„FRED APIå¯†é’¥ï¼Œç”¨äºå¢å¼ºç»æµåˆ¶åº¦æ£€æµ‹
    fred_api_key = "FRED API"
    
    # åˆ›å»ºå¹¶è¿è¡Œå…·æœ‰å®Œæ•´ç»æµæ•°æ®çš„å¢å¼ºç³»ç»Ÿ
    options_system = OptionsFlowPredictiveSystem(symbols=symbols, fred_api_key=fred_api_key)
    
    # è¿è¡Œå®Œæ•´åˆ†æ
    results = options_system.run_complete_analysis()
    
    if results:
        print(f"\nğŸ‰ å¢å¼ºç³»ç»ŸæˆåŠŸå®Œæˆæ‰€æœ‰é˜¶æ®µï¼")
        print(f"ğŸ“Š å­¦æœ¯çº§ç‰¹å¾ã€æ¨¡å‹å’Œä¿¡å·å·²å‡†å¤‡å¥½ç”¨äºå®ç›˜äº¤æ˜“")
        print(f"ğŸ”¬ æ€§èƒ½æ”¹è¿›å·²å®æ–½å¹¶éªŒè¯")
        print(f"ğŸ’° ç»æµåˆ¶åº¦æ£€æµ‹: ä½¿ç”¨FREDæ•°æ®æ¿€æ´»")
        print(f"ğŸ”§ XGBoostè®­ç»ƒ: æ­£å¸¸å·¥ä½œï¼ˆé”™è¯¯å·²ä¿®å¤ï¼‰")
        print(f"ğŸ› ï¸  æ•°æ®æ³„æ¼: å·²ä¿®å¤ï¼ˆç›®æ ‡å˜é‡å·²æ’é™¤ï¼‰")
        print(f"ğŸ“ˆ ä¿¡å·è§£é‡Š: æä¾›ç»¼åˆåˆ†æ")
        
        # æ˜¾ç¤ºæ ·æœ¬é¢„æµ‹
        if 'features' in results and not results['features'].empty:
            print(f"\nğŸ“ˆ å¢å¼ºç‰¹å¾å½¢çŠ¶: {results['features'].shape}")
            print(f"ğŸ¯ æ‰©å±•å†å²çª—å£: {results['features'].shape[0]} ä¸ªæ ·æœ¬")
            
            # å¦‚æœå¯ç”¨ï¼Œæ˜¾ç¤ºåˆ¶åº¦ç‰¹å¾
            regime_cols = [col for col in results['features'].columns if 'regime' in col]
            if regime_cols:
                print(f"ğŸ›ï¸  ç»æµåˆ¶åº¦ç‰¹å¾: {len(regime_cols)} ä¸ªæŒ‡æ ‡")
                for regime_col in regime_cols[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                    unique_vals = results['features'][regime_col].nunique()
                    print(f"    â€¢ {regime_col}: {unique_vals} ä¸ªä¸åŒçš„åˆ¶åº¦çŠ¶æ€")
            
        if 'signals' in results:
            print(f"\nğŸš¨ ä¸º {len(results['signals'])} ä¸ªç¬¦å·ç”Ÿæˆå¢å¼ºä¿¡å·")
            
        if 'models' in results:
            working_models = [k for k, v in results['models'].items() if v is not None]
            print(f"\nğŸ¤– æˆåŠŸè®­ç»ƒçš„æ¨¡å‹: {', '.join(working_models)}")
            
        if 'performance' in results and results['performance']:
            daily_bps = results['performance'].get('avg_daily_return_bps', None)
            if daily_bps is not None:
                if daily_bps >= 40:
                    print(f"ğŸ† å­¦æœ¯ç›®æ ‡å·²å®ç°: {daily_bps:.2f} ä¸ªåŸºç‚¹æ¯æ—¥ï¼")
                elif daily_bps >= 20:
                    print(f"ğŸ“ˆ æ¥è¿‘å­¦æœ¯ç›®æ ‡: {daily_bps:.2f} ä¸ªåŸºç‚¹æ¯æ—¥")
                else:
                    print(f"ğŸ“Š å½“å‰æ€§èƒ½: {daily_bps:.2f} ä¸ªåŸºç‚¹æ¯æ—¥")
            
    else:
        print("âŒ å¢å¼ºåˆ†æå¤±è´¥ã€‚è¯·æ£€æŸ¥æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯ã€‚")

if __name__ == "__main__":
    main()
